{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "import csv\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Input, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.callbacks import *\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "## I think that this should be enough for most people...\n",
    "#session = tf.Session()\n",
    "\n",
    "## ... but my Windows machine needs this to run\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple confirmation function\n",
    "def confirm(question):\n",
    "    reply = str(input(question + \" (y/n): \")).lower().strip()\n",
    "    if reply[0] == \"y\":\n",
    "        return True\n",
    "    if reply[0] == \"n\":\n",
    "        return False\n",
    "    else:\n",
    "        return confirm(\"Choices are \")\n",
    "    \n",
    "# Dice\n",
    "smooth = 1.\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original uncropped image dimensions\n",
    "ORIGINAL_IMG_HEIGHT = 1024\n",
    "ORIGINAL_IMG_WIDTH = 1024\n",
    "\n",
    "# Resized uncropped image dimensions for training\n",
    "IMG_HEIGHT = 96\n",
    "IMG_WIDTH = 96\n",
    "\n",
    "# Number of training set images to use for validation\n",
    "VAL_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate training sets\n",
    "train_X = []\n",
    "train_Y = []\n",
    "\n",
    "with open(\"training_images.csv\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "    for row in csv_reader:\n",
    "        # Load Images\n",
    "        image = Image.open(\"uncropped_train_images/\" + row[0] + \".png\", \"r\")\n",
    "        mask = Image.open(\"uncropped_train_masks/\" + row[0] + \"_mask.png\", \"r\")\n",
    "\n",
    "        image_pixelarray = np.array(list(image.getdata(0)))\n",
    "        image_pixelarray = np.reshape(image_pixelarray, (ORIGINAL_IMG_WIDTH,ORIGINAL_IMG_HEIGHT))\n",
    "        image_pixelarray = np.array(Image.fromarray(image_pixelarray).resize((IMG_WIDTH, IMG_HEIGHT)))\n",
    "        train_X.append(image_pixelarray)\n",
    "\n",
    "        mask_pixelarray = np.array(list(mask.getdata(0)))\n",
    "        mask_pixelarray = np.reshape(mask_pixelarray, (ORIGINAL_IMG_WIDTH,ORIGINAL_IMG_HEIGHT))            \n",
    "        mask_pixelarray = np.array(Image.fromarray(mask_pixelarray).resize((IMG_WIDTH, IMG_HEIGHT)))\n",
    "        train_Y.append(mask_pixelarray)\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "train_Y = np.array(train_Y)\n",
    "print(\"train_X_shape : \", train_X.shape)\n",
    "print(\"train_Y_shape : \", train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a few uncropped images with their masks\n",
    "for i in range(5):\n",
    "    figure, ax = plt.subplots(1,2)\n",
    "    ax[0].imshow(train_X[i], cmap=\"gray\")\n",
    "    ax[1].imshow(train_Y[i], cmap=\"gray\")\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into training & validation, without shuffling\n",
    "\n",
    "X = train_X[:len(train_X)-VAL_SIZE]\n",
    "Y = train_Y[:len(train_Y)-VAL_SIZE]\n",
    "val_X = train_X[len(train_X)-VAL_SIZE:]\n",
    "val_Y = train_Y[len(train_Y)-VAL_SIZE:]\n",
    "\n",
    "X = X[:,:,:,np.newaxis] / 255\n",
    "Y = Y[:,:,:,np.newaxis] / 255\n",
    "print(\"X shape : \", X.shape)\n",
    "print(\"Y shape : \", Y.shape)\n",
    "\n",
    "val_X = val_X[:,:,:,np.newaxis] / 255\n",
    "val_Y = val_Y[:,:,:,np.newaxis] / 255\n",
    "print(\"val_X shape : \", val_X.shape)\n",
    "print(\"val_Y shape : \", val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unet model\n",
    "\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "\n",
    "conv1 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "conv1 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "conv2 = Conv2D(64,(3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
    "conv3 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "# Skipped (4)\n",
    "\n",
    "conv5 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n",
    "conv5 = Dropout(0.2)(conv5)\n",
    "conv5 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(conv5)\n",
    "\n",
    "# Skipped (6)\n",
    "\n",
    "up7 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\")(conv5), conv3], axis=3)\n",
    "conv7 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(up7)\n",
    "conv7 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(conv7)\n",
    "\n",
    "up8 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding=\"same\")(conv7), conv2], axis=3)\n",
    "conv8 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(up8)\n",
    "conv8 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(conv8)\n",
    "\n",
    "up9 = concatenate([Conv2DTranspose(16, (2, 2), strides=(2, 2), padding=\"same\")(conv8), conv1], axis=3)\n",
    "conv9 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(up9)\n",
    "conv9 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(conv9)\n",
    "\n",
    "conv10 = Conv2D(1, (1, 1), activation=\"sigmoid\")(conv9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[conv10])\n",
    "model.compile(optimizer=Adam(lr = 1e-5), loss=dice_coef_loss, metrics=[dice_coef]) #(lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filename to save best model\n",
    "bestmodelh5 = \"model/bestmodel.h5\"\n",
    "# bestmodelh5 = \"model/CXRCropper_Pretrained.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the number of epochs and batch size\n",
    "EPOCHS = 40\n",
    "BS = 2\n",
    "\n",
    "# Construct the training image generator\n",
    "aug = keras.preprocessing.image.ImageDataGenerator() # No augmentation applied\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=150, verbose=2),\n",
    "    ModelCheckpoint(filepath=bestmodelh5, monitor=\"val_loss\", \n",
    "                    save_best_only=True, verbose=2)   \n",
    "]\n",
    "\n",
    "# Check for previously trained weights to avoid accidental overwrite\n",
    "good_to_go = False\n",
    "if (os.path.exists(bestmodelh5)) :\n",
    "    if (confirm(\"Overwrite previous h5\")):\n",
    "        good_to_go = True\n",
    "else :\n",
    "    good_to_go = True\n",
    "\n",
    "# Do training\n",
    "if (good_to_go):        \n",
    "    results = model.fit_generator(\n",
    "                aug.flow(X, Y, batch_size=BS),\n",
    "                validation_data=(val_X, val_Y),\n",
    "                epochs=EPOCHS,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1,\n",
    "                steps_per_epoch=len(X) // BS,\n",
    "                use_multiprocessing=False, \n",
    "                workers=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Dice accuracy and losses\n",
    "print(results.history.keys())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(results.history[\"dice_coef\"], \"orange\", label=\"Training accuracy\")\n",
    "plt.plot(results.history[\"val_dice_coef\"], \"blue\", label=\"Validation accuracy\")\n",
    "plt.plot(results.history[\"loss\"], \"red\", label=\"Training loss\")\n",
    "plt.plot(results.history[\"val_loss\"], \"green\", label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAIT! THINK ABOUT THIS!!!\n",
    "# Load previous weights\n",
    "\n",
    "if (confirm(\"Load previous weights\")):\n",
    "    model.load_weights(bestmodelh5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR PNG FILES (Cell 1 of 2)\n",
    "# Run to do crop on PNG files and output cropped_images and cropped_images_masks\n",
    "\n",
    "# Get list of testing PNGs\n",
    "list_of_testing_files = []\n",
    "list_of_testing_files_location = []\n",
    "\n",
    "for dirpath, dirnames, files in os.walk(\"uncropped_test_png\"):\n",
    "    for name in files:\n",
    "        list_of_testing_files.append(name)\n",
    "        list_of_testing_files_location.append(os.path.join(dirpath, name))\n",
    "\n",
    "print(\"Total testing files:\", (len(list_of_testing_files)))\n",
    "\n",
    "# Create testing data images (test_X)\n",
    "test_X = []\n",
    "test_X_filename = []\n",
    "\n",
    "for f in range(len(list_of_testing_files_location)):\n",
    "    # Load Images\n",
    "    dataset = Image.open(list_of_testing_files_location[f], \"r\")\n",
    "    test_image = np.array(list(dataset.getdata(0)))\n",
    "    test_image = np.reshape(test_image, (ORIGINAL_IMG_WIDTH,ORIGINAL_IMG_HEIGHT))\n",
    "    test_image = np.array(Image.fromarray(test_image).resize((IMG_WIDTH, IMG_HEIGHT)))\n",
    "    test_X.append(test_image)\n",
    "    test_X_filename.append(list_of_testing_files[f])\n",
    "    \n",
    "test_X = np.array(test_X)\n",
    "\n",
    "# Display one DICOM file\n",
    "plt.imshow(test_X[0], cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "test_X = test_X[:,:,:,np.newaxis] / 255\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR PNG FILES (Cell 2 of 2)\n",
    "# Run to do crop on PNG files and output cropped_images and cropped_images_masks\n",
    "\n",
    "# Predict on test set\n",
    "pred_Y = model.predict(test_X)\n",
    "\n",
    "# Disable interactive plot\n",
    "plt.ioff()\n",
    "\n",
    "# Store crop parameters\n",
    "# Crop parameters stores the crop dimensions of every test image - so that the results can be \"uncropped\" later\n",
    "crop_parameters = []\n",
    "\n",
    "for i in range(test_X.shape[0]):\n",
    "    img = pred_Y[i, :, :, 0]\n",
    "    # Since training was at 96x96, we enlarge the predicted mask to 1024x1024\n",
    "    img = np.array(Image.fromarray(img).resize((ORIGINAL_IMG_WIDTH, ORIGINAL_IMG_HEIGHT)))   \n",
    "    # Set the cutoff at 0.5 between True (within mask) and False (outside mask)\n",
    "    img = img > 0.5\n",
    "    \n",
    "    # Get cropping parameters from lung mask \n",
    "    segmented = np.where(img[:,]==True)\n",
    "    \n",
    "    # padding determines how many pixels outside the predicted mask we want to accept into the final mask\n",
    "    # As most CXRs have a little bit of chest wall / air around them, we simply choose 50 pixels\n",
    "    padding = 50\n",
    "    \n",
    "    # TODO: Insert catch for small segmentations, maybe <30 pixel count?\n",
    "    \n",
    "    try:\n",
    "        top = np.amin(segmented[0]) - padding\n",
    "        bottom = np.amax(segmented[0]) + padding\n",
    "        left = np.amin(segmented[1]) - padding\n",
    "        right = np.amax(segmented[1]) + padding\n",
    "    except ValueError:  # Raised if segmented is empty.\n",
    "        top = 0\n",
    "        bottom = ORIGINAL_IMG_HEIGHT - 1\n",
    "        left = 0    \n",
    "        right = ORIGINAL_IMG_WIDTH - 1 \n",
    "        \n",
    "    # Make sure +padding doesn\"t exceed np array size\n",
    "    if top < 0:\n",
    "        top = 0\n",
    "    if bottom > ORIGINAL_IMG_HEIGHT:\n",
    "        bottom = ORIGINAL_IMG_HEIGHT - 1\n",
    "    if left < 0:\n",
    "        left = 0\n",
    "    if right > ORIGINAL_IMG_WIDTH:\n",
    "        right = ORIGINAL_IMG_WIDTH - 1    \n",
    "\n",
    "    # Create crop_parameter line    \n",
    "    crop_parameters_row = [test_X_filename[i], top, left, bottom, right]\n",
    "    crop_parameters.append(crop_parameters_row)\n",
    "    \n",
    "    # Lung is a new image that used to display the predicted mask\n",
    "    lung = np.zeros((ORIGINAL_IMG_WIDTH,ORIGINAL_IMG_HEIGHT))\n",
    "    lung[:,:] = False\n",
    "    lung[top:bottom,left:right] = True\n",
    "    \n",
    "    # Load the original PNG into image1\n",
    "    dataset = Image.open(\"uncropped_test_png/\" + test_X_filename[i], \"r\")\n",
    "    image1 = np.array(list(dataset.getdata(0)))\n",
    "    image1 = np.reshape(image1, (ORIGINAL_IMG_WIDTH,ORIGINAL_IMG_HEIGHT))\n",
    "    # dataset = pydicom.dcmread(\"uncropped_test_dicom/\" + test_X_filename[i])\n",
    "    # image1 = np.array(Image.fromarray(dataset.pixel_array).resize((ORIGINAL_IMG_WIDTH, ORIGINAL_IMG_HEIGHT)))\n",
    "    \n",
    "    # Crop and save PNG\n",
    "    # Generate and save cropped images\n",
    "    image2 = image1[top:bottom,left:right] \n",
    "    im2 = Image.fromarray(image2)\n",
    "    im2 = im2.resize((1024,1024),Image.BICUBIC)\n",
    "    im2 = im2.convert(\"RGB\") # Reduces each channel from 16-bit to 8-bit\n",
    "    im2.save(\"cropped_test_images/\"+test_X_filename[i]+\"_lung.png\") \n",
    "\n",
    "    # Generate and save original images with masks for result exploration\n",
    "    fig, ax = plt.subplots(1,3,figsize = (16,12))\n",
    "    # Original PNG\n",
    "    ax[0].imshow(image1, cmap = \"gray\")\n",
    "    # Original PNG with cropped area (predicted mask + padding)\n",
    "    ax[1].imshow(image1, cmap = \"gray\", interpolation = \"none\")\n",
    "    ax[1].imshow(lung, cmap = \"viridis\", interpolation = \"none\", alpha = 0.5)\n",
    "    # Predicted mask\n",
    "    ax[2].imshow(img, cmap = \"gray\")\n",
    "    fig.savefig(\"cropped_test_images_masks/\"+test_X_filename[i]+\"_overlay.png\", bbox_inches=\"tight\", dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Display within notebook\n",
    "    fig, ax = plt.subplots(1,4,figsize = (20,12))\n",
    "    # Original PNG\n",
    "    ax[0].imshow(image1, cmap = \"gray\")\n",
    "    # Original PNG with cropped area (predicted mask + padding)\n",
    "    ax[1].imshow(image1, cmap = \"gray\", interpolation = \"none\")\n",
    "    ax[1].imshow(lung, cmap = \"viridis\", interpolation = \"none\", alpha = 0.5)\n",
    "    # Predicted mask\n",
    "    ax[2].imshow(img, cmap = \"gray\")\n",
    "    ax[3].imshow(im2, cmap = \"gray\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "# Save crop parameters\n",
    "np.savetxt(\"cropped_test_images/crop_parameters.csv\", crop_parameters, delimiter=\",\", fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DICOM FILES (Cell 1 of 2)\n",
    "# Run to do crop on DICOM files and output cropped_images and cropped_images_masks\n",
    "\n",
    "# Get list of testing DICOMs\n",
    "list_of_testing_files = []\n",
    "list_of_testing_files_location = []\n",
    "\n",
    "for dirpath, dirnames, files in os.walk(\"uncropped_test_dicom\"):\n",
    "    for name in files:\n",
    "        list_of_testing_files.append(name)\n",
    "        list_of_testing_files_location.append(os.path.join(dirpath, name))\n",
    "\n",
    "print(\"Total testing files:\", (len(list_of_testing_files)))\n",
    "\n",
    "# Create testing data images (test_X)\n",
    "test_X = []\n",
    "test_X_filename = []\n",
    "\n",
    "for f in range(len(list_of_testing_files_location)):\n",
    "    dataset = pydicom.dcmread(list_of_testing_files_location[f])\n",
    "    test_image = np.array(Image.fromarray(dataset.pixel_array).resize((IMG_WIDTH, IMG_HEIGHT)))\n",
    "    test_X.append(test_image)\n",
    "    test_X_filename.append(list_of_testing_files[f])\n",
    "    \n",
    "test_X = np.array(test_X)\n",
    "\n",
    "# Display one DICOM file\n",
    "plt.imshow(test_X[0], cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "test_X = test_X[:,:,:,np.newaxis] / 255\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# FOR DICOM FILES (Cell 2 of 2)\n",
    "# Run to do crop on DICOM files and output cropped_images and cropped_images_masks\n",
    "\n",
    "# Predict on test set\n",
    "pred_Y = model.predict(test_X)\n",
    "\n",
    "# Disable interactive plot\n",
    "plt.ioff()\n",
    "\n",
    "# Store crop parameters\n",
    "# Crop parameters stores the crop dimensions of every test image - so that the results can be \"uncropped\" later\n",
    "crop_parameters = []\n",
    "\n",
    "for i in range(test_X.shape[0]):\n",
    "    img = pred_Y[i, :, :, 0]\n",
    "    # Since training was at 96x96, we enlarge the predicted mask to 1024x1024\n",
    "    img = np.array(Image.fromarray(img).resize((ORIGINAL_IMG_WIDTH, ORIGINAL_IMG_HEIGHT)))   \n",
    "    # Set the cutoff at 0.5 between True (within mask) and False (outside mask)\n",
    "    img = img > 0.5\n",
    "    \n",
    "    # Get cropping parameters from lung mask \n",
    "    segmented = np.where(img[:,]==True)\n",
    "    \n",
    "    # padding determines how many pixels outside the predicted mask we want to accept into the final mask\n",
    "    # As most CXRs have a little bit of chest wall / air around them, we simply choose 50 pixels\n",
    "    padding = 50\n",
    "    \n",
    "    # TODO: Insert catch for small segmentations, maybe <30 pixel count?\n",
    "    \n",
    "    try:\n",
    "        top = np.amin(segmented[0]) - padding\n",
    "        bottom = np.amax(segmented[0]) + padding\n",
    "        left = np.amin(segmented[1]) - padding\n",
    "        right = np.amax(segmented[1]) + padding\n",
    "    except ValueError:  # Raised if segmented is empty.\n",
    "        top = 0\n",
    "        bottom = ORIGINAL_IMG_HEIGHT - 1\n",
    "        left = 0    \n",
    "        right = ORIGINAL_IMG_WIDTH - 1 \n",
    "        \n",
    "    # Make sure +padding doesn\"t exceed np array size\n",
    "    if top < 0:\n",
    "        top = 0\n",
    "    if bottom > ORIGINAL_IMG_HEIGHT:\n",
    "        bottom = ORIGINAL_IMG_HEIGHT - 1\n",
    "    if left < 0:\n",
    "        left = 0\n",
    "    if right > ORIGINAL_IMG_WIDTH:\n",
    "        right = ORIGINAL_IMG_WIDTH - 1    \n",
    "\n",
    "    # Create crop_parameter line    \n",
    "    crop_parameters_row = [test_X_filename[i], top, left, bottom, right]\n",
    "    crop_parameters.append(crop_parameters_row)\n",
    "    \n",
    "    # Lung is a new image that used to display the predicted mask\n",
    "    lung = np.zeros((ORIGINAL_IMG_WIDTH,ORIGINAL_IMG_HEIGHT))\n",
    "    lung[:,:] = False\n",
    "    lung[top:bottom,left:right] = True\n",
    "    \n",
    "    # Load the original DICOM into image1\n",
    "    dataset = pydicom.dcmread(\"uncropped_test_dicom/\" + test_X_filename[i])\n",
    "    image1 = np.array(Image.fromarray(dataset.pixel_array).resize((ORIGINAL_IMG_WIDTH, ORIGINAL_IMG_HEIGHT)))\n",
    "    \n",
    "    # Crop and save PNG\n",
    "    # Generate and save cropped images\n",
    "    image2 = image1[top:bottom,left:right] \n",
    "    im2 = Image.fromarray(image2)\n",
    "    im2 = im2.resize((1024,1024),Image.BICUBIC)\n",
    "    im2.save(\"cropped_test_images/\"+test_X_filename[i]+\"_lung.png\") \n",
    "\n",
    "    # Generate and save original images with masks for result exploration\n",
    "    fig, ax = plt.subplots(1,3,figsize = (16,12))\n",
    "    # Original DICOM\n",
    "    ax[0].imshow(image1, cmap = \"gray\")\n",
    "    # Original DICOM with cropped area (predicted mask + padding)\n",
    "    ax[1].imshow(image1, cmap = \"gray\", interpolation = \"none\")\n",
    "    ax[1].imshow(lung, cmap = \"viridis\", interpolation = \"none\", alpha = 0.5)\n",
    "    # Predicted mask\n",
    "    ax[2].imshow(img, cmap = \"gray\")\n",
    "    fig.savefig(\"cropped_test_images_masks/\"+test_X_filename[i]+\"_overlay.png\", bbox_inches=\"tight\", dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Display within notebook\n",
    "    fig, ax = plt.subplots(1,4,figsize = (20,12))\n",
    "    # Original DICOM\n",
    "    ax[0].imshow(image1, cmap = \"gray\")\n",
    "    # Original DICOM with cropped area (predicted mask + padding)\n",
    "    ax[1].imshow(image1, cmap = \"gray\", interpolation = \"none\")\n",
    "    ax[1].imshow(lung, cmap = \"viridis\", interpolation = \"none\", alpha = 0.5)\n",
    "    # Predicted mask\n",
    "    ax[2].imshow(img, cmap = \"gray\")\n",
    "    ax[3].imshow(im2, cmap = \"gray\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "# Save crop parameters\n",
    "np.savetxt(\"cropped_test_images/crop_parameters.csv\", crop_parameters, delimiter=\",\", fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
